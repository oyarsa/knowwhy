{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb8ca9-b5ca-4a2d-be35-a93e6badf4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from collections.abc import Callable\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804d28e-b633-4310-9874-500f2788e7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../artifacts/human_eval_cache.pkl\", \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "\n",
    "len(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e2f6e-23c8-449a-88c2-297d7d5f46e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = list(cache.keys())\n",
    "values = list(cache.values())\n",
    "value_keys = list(values[0].keys())\n",
    "value_values = list(values[0].values())\n",
    "\n",
    "print(\n",
    "    f\"Key: {type(keys[0])}\",\n",
    "    f\"Key elements: {[type(k) for k in keys[0]]}\",\n",
    "    f\"Value: {type(values[0])}\",\n",
    "    f\"Value key: {type(value_keys[0])}\",\n",
    "    f\"Value value: {type(value_values[0])}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a33a93-6427-49d3-a20a-f8a6ae8117f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Key:\")\n",
    "pprint(keys[0])\n",
    "print()\n",
    "print(\"Value:\")\n",
    "pprint(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1bf3e-7f8d-4de7-80a5-c97fa04d2228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hashes = [hash(t) for t in cache]\n",
    "len(hashes), len(set(hashes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb48c4-0eff-49ff-a896-bde0b38b1ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"q\": q,\n",
    "            \"a\": a,\n",
    "            \"n\": n,\n",
    "            \"ann\": sorted(ann[\"val_annotations\"]),\n",
    "        }\n",
    "        for (q, a, n), ann in cache.items()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7950be-de07-41e8-8858-1f4042ee252c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f78069-c1d0-4bcd-96f9-197ec137f66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"ann\"] = df[\"ann\"].map(lambda x: [i + 2 for i in x])\n",
    "df[\"ann\"].explode().agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c543b19-5b84-44ac-8aa7-7016d6e3c14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"std\"] = df[\"ann\"].map(np.std)\n",
    "df[\"std\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab08276-65e9-4ea4-9c59-ff7bbb7d26b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c338a67-b426-4fbc-b735-70c54de9c7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df[\"ann\"].map(lambda x: x == [0, 2, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13949b69-8687-4970-ba92-455ba87e2a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = [0, 2, 4]\n",
    "np.diff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d248d4a-3782-4e36-89dd-08dfdebe6bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listeq(lst: list[int]) -> Callable[[list[int]], bool]:\n",
    "    def eq(el: list[int]) -> bool:\n",
    "        return lst == el\n",
    "\n",
    "    return eq\n",
    "\n",
    "\n",
    "def entropy(data: list[int]) -> float:\n",
    "    counts = np.bincount(data)\n",
    "    p = counts / len(data)\n",
    "    return -np.sum(p[p > 0] * np.log2(p[p > 0]))\n",
    "\n",
    "\n",
    "def gini_coefficient(data: list[int]) -> float:\n",
    "    if np.all(data == data[0]) or np.isclose(np.sum(data), 0):\n",
    "        return 0\n",
    "\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "\n",
    "    return (\n",
    "        2 * np.sum(np.arange(1, n + 1) * sorted_data) / (n * np.sum(sorted_data))\n",
    "    ) - (n + 1) / n\n",
    "\n",
    "\n",
    "def calculate_alpha(ratings: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Krippendorff's Alpha for a single example with nominal data.\n",
    "\n",
    "    :param ratings: List of ratings (integers or strings) for a single example by different raters.\n",
    "    :return: Krippendorff's Alpha as a float.\n",
    "    \"\"\"\n",
    "    arratings = np.array(ratings)\n",
    "\n",
    "    # Count the occurrences of each rating\n",
    "    _, counts = np.unique(arratings, return_counts=True)\n",
    "    n = len(arratings)\n",
    "\n",
    "    # Calculate observed disagreement (D_o)\n",
    "    D_o = sum(c * (c - 1) for c in counts)  # Pairwise comparisons for each category\n",
    "    D_o = 0 if n <= 1 else 1 - D_o / (n * (n - 1))\n",
    "\n",
    "    # Calculate expected disagreement (D_e)\n",
    "    D_e = 1 - sum((counts / n) ** 2)  # Prob. of random agreement for each category\n",
    "\n",
    "    # Calculate Krippendorff's Alpha\n",
    "    return 1 - D_o / D_e if D_e != 0 else 1  # Handle division by zero\n",
    "\n",
    "\n",
    "def observed_agreement_single_item(coder_codes: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the observed agreement among coders for a single item with K categories\n",
    "    according to the provided formula, using Counter for category counts and a\n",
    "    comprehension for agreement calculation.\n",
    "\n",
    "    Args:\n",
    "        coder_codes: A list of integers representing the codes assigned by each coder.\n",
    "\n",
    "    Returns:\n",
    "        The observed agreement as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    n_coders = len(coder_codes)\n",
    "    category_counts = Counter(coder_codes)\n",
    "\n",
    "    agreement = sum(n_k * (n_k - 1) for n_k in category_counts.values())\n",
    "\n",
    "    return agreement / (n_coders * (n_coders - 1))  # Normalize by total comparisons\n",
    "\n",
    "\n",
    "def calculate_agreement(\n",
    "    data: list[int], *, labels: list[int], weight_type: str\n",
    ") -> float:\n",
    "    \"\"\"Calculte the agreement between multiple raters on a single item.\n",
    "\n",
    "    The calculation is based on the average weighted difference between all pairs of\n",
    "    values in `data`. `labels` is used to determine the possible values in the data in\n",
    "    case the data doesn't represent all of them.\n",
    "\n",
    "    The final value is normalized to the range [0, 1] by dividing by the maximum possible\n",
    "    weighted difference.\n",
    "\n",
    "    Args:\n",
    "        data:\n",
    "            A list of integers representing the ratings from different raters. There\n",
    "            must be at least two items.\n",
    "        labels:\n",
    "            A list of integers specifying all potential rating values. This is used\n",
    "            to determine the range for normalization.\n",
    "        weight_type:\n",
    "            A string indicating the weighting scheme to use. Valid options: \"quadratic\",\n",
    "            \"linear\", \"binary\".\n",
    "\n",
    "    Returns:\n",
    "        A float in the range [0, 1] representing the normalized agreement between\n",
    "        raters.  A value of 0 indicates maximum disagreement, and a value of 1 indicates\n",
    "        perfect agreement.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            If `data` contains fewer than two values or if an invalid  `weight_type` is\n",
    "            provided.\n",
    "    \"\"\"\n",
    "    if len(data) < 2:\n",
    "        raise ValueError(\"Data must contain at least two values.\")\n",
    "\n",
    "    combinations = list(itertools.combinations(data, 2))\n",
    "\n",
    "    if weight_type == \"quadratic\":\n",
    "        disagreement = sum((x - y) ** 2 for x, y in combinations)\n",
    "        normaliser = (max(labels) - min(labels)) ** 2\n",
    "    elif weight_type == \"linear\":\n",
    "        disagreement = sum(abs(x - y) for x, y in combinations)\n",
    "        normaliser = abs(max(labels) - min(labels))\n",
    "    elif weight_type == \"binary\":\n",
    "        disagreement = sum(x != y for x, y in combinations)\n",
    "        normaliser = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid weight type: {weight_type}\")\n",
    "\n",
    "    k = disagreement / normaliser / len(combinations)\n",
    "    return 1 - k\n",
    "\n",
    "\n",
    "def randolph(data: list[int], *, labels: list[int]) -> float:\n",
    "    # Make sure the labels start at 0\n",
    "    if min(labels) != 0:\n",
    "        data = [x - min(labels) for x in data]\n",
    "\n",
    "    table = np.zeros(len(labels))\n",
    "    np.add.at(table, data, 1)\n",
    "\n",
    "    n_rat = table.sum()\n",
    "\n",
    "    table2 = table**2\n",
    "    p_rat = (table2.sum() - n_rat) / (n_rat * (n_rat - 1.0))\n",
    "    p_mean = p_rat.mean()\n",
    "\n",
    "    # Uniform distribution instead of marginal frequency of categories so it's defined\n",
    "    # for single sample. Marginal frequency will sometimes give p_mean_exp = 0, so the\n",
    "    # the numerator will be zero and the kappa will be undefined.\n",
    "    p_mean_exp = 1 / len(labels)\n",
    "    kappa = (p_mean - p_mean_exp) / (1 - p_mean_exp)\n",
    "    return kappa\n",
    "\n",
    "\n",
    "def consensus(data: list[int], *, labels: list[int]) -> float:\n",
    "    \"\"\"From \"Consensus and dissention: A measure of ordinal dispersion (2007)\"\n",
    "    By William J. Tastle, Mark J. Wierman.\n",
    "    \"\"\"\n",
    "    # Make sure the labels start at 0 for bincount\n",
    "    data = [x - min(labels) for x in data]\n",
    "    p = np.bincount(data, minlength=len(labels)) / len(data)\n",
    "\n",
    "    d_x = max(labels) - min(labels)\n",
    "    u_x = (p * labels).sum()\n",
    "\n",
    "    # Page 8 \n",
    "    return 1 + sum(\n",
    "        p[i] * math.log2(1 - (abs(labels[i] - u_x) / d_x))\n",
    "        for i in range(len(labels))\n",
    "        if p[i] > 0\n",
    "    )\n",
    "\n",
    "\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "metrics = dict(\n",
    "    entropy=lambda x: x[\"ann\"].map(entropy),\n",
    "    gini=lambda x: x[\"ann\"].map(gini_coefficient),\n",
    "    alpha=lambda x: x[\"ann\"].map(calculate_alpha),\n",
    "    agr=lambda x: x[\"ann\"].map(observed_agreement_single_item),\n",
    "    agr_q=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"quadratic\", labels=labels\n",
    "    ),\n",
    "    agr_l=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"linear\", labels=labels\n",
    "    ),\n",
    "    agr_b=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"binary\", labels=labels\n",
    "    ),\n",
    "    randolph=lambda x: x[\"ann\"].apply(randolph, labels=labels),\n",
    "    consensus=lambda x: x[\"ann\"].apply(consensus, labels=labels),\n",
    ")\n",
    "\n",
    "dd = df.assign(**metrics)\n",
    "examples = [\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 1],\n",
    "    [1, 2, 3],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 2],\n",
    "    [0, 0, 3],\n",
    "    [0, 0, 4],\n",
    "    [0, 2, 4],\n",
    "    [0, 0, 0],\n",
    "    [0, 4, 4, 4, 4, 4],\n",
    "    [0, 1, 2, 3, 4, 4],\n",
    "]\n",
    "pd.concat(\n",
    "    [dd[dd[\"ann\"].map(listeq(lst))].iloc[0] for lst in examples],\n",
    "    axis=1,\n",
    ").transpose()[[\"ann\", *metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1336124-a2f8-44ae-939b-3bbd9f355520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd[dd.ann.map(len) == 6].drop_duplicates(\"ann\")[\n",
    "    [\"ann\", *metrics]\n",
    "].sort_values(\"agr\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fd08d-33ac-4d2a-b2e9-8bf8428c3380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [1,2,3,4,5]\n",
    "ratings = [\n",
    "    [1, 1, 1, 5, 5, 5],\n",
    "    [1, 5],\n",
    "    [1, 4],\n",
    "    [1, 3],\n",
    "    [1, 2],\n",
    "    [1, 1]\n",
    "]\n",
    "data = [\n",
    "    {\n",
    "        'ratings': r,\n",
    "        'agr_q': calculate_agreement(r, weight_type='quadratic', labels=labels),\n",
    "        'agr_l': calculate_agreement(r, weight_type='linear', labels=labels),\n",
    "        'agr_b': calculate_agreement(r, weight_type='binary', labels=labels),\n",
    "        'randolph': randolph(r, labels=labels),\n",
    "        'consensus': consensus(r, labels=labels),\n",
    "    }\n",
    "    for r in ratings\n",
    "]\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303923d0-69de-4104-a30c-86222d06a6de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a920b-449e-46a8-8ad4-8c3a51e70731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd.sort_values('consensus').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdd3b1-b045-48a1-b5cc-9e064728dd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dist(df: pd.DataFrame, col: str) -> None:\n",
    "    plt.figure(figsize=(3.5, 2.5))\n",
    "    plt.hist(df[col], bins=10, edgecolor=\"black\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603294d-58d7-4bdf-ba09-6590639a89bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [\"consensus\", \"agr_q\", \"agr_l\", \"agr_b\"]\n",
    "for col in metrics:\n",
    "    plot_dist(dd, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e23c2e-d9cb-49e4-8ee9-2104bed7a32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd[metrics].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade2fe2-f066-4e2d-bcb5-17b6bd8acf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dist(df: pd.DataFrame, metrics: list) -> None:\n",
    "    rows = len(metrics) // 2  # Calculate rows (assuming you want 2 columns)\n",
    "    cols = 2 \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(7, 5))  # Adjust figsize as needed\n",
    "\n",
    "    for i, m in enumerate(metrics):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        ax = axes[row, col]\n",
    "        ax.hist(df[m], bins=10, edgecolor=\"black\")\n",
    "        ax.set_xlabel(m)\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.set_title(f\"Distribution of {m}\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()  # Prevent overlapping\n",
    "    plt.show()\n",
    "\n",
    "metrics = [\"consensus\", \"agr_q\", \"agr_l\", \"agr_b\"]\n",
    "plot_dist(dd, metrics)  # Assuming 'dd' is your DataFrame \n",
    "dd[metrics].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4e423-7668-4ef7-ae87-8b676b2fd94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all(m in dd.columns for m in metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
