{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb8ca9-b5ca-4a2d-be35-a93e6badf4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from collections.abc import Callable\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804d28e-b633-4310-9874-500f2788e7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../artifacts/human_eval_cache.pkl\", \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "\n",
    "len(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e2f6e-23c8-449a-88c2-297d7d5f46e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = list(cache.keys())\n",
    "values = list(cache.values())\n",
    "value_keys = list(values[0].keys())\n",
    "value_values = list(values[0].values())\n",
    "\n",
    "print(\n",
    "    f\"Key: {type(keys[0])}\",\n",
    "    f\"Key elements: {[type(k) for k in keys[0]]}\",\n",
    "    f\"Value: {type(values[0])}\",\n",
    "    f\"Value key: {type(value_keys[0])}\",\n",
    "    f\"Value value: {type(value_values[0])}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a33a93-6427-49d3-a20a-f8a6ae8117f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Key:\")\n",
    "pprint(keys[0])\n",
    "print()\n",
    "print(\"Value:\")\n",
    "pprint(values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1bf3e-7f8d-4de7-80a5-c97fa04d2228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hashes = [hash(t) for t in cache]\n",
    "len(hashes), len(set(hashes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb48c4-0eff-49ff-a896-bde0b38b1ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"q\": q,\n",
    "            \"a\": a,\n",
    "            \"n\": n,\n",
    "            \"ann\": sorted(ann[\"val_annotations\"]),\n",
    "        }\n",
    "        for (q, a, n), ann in cache.items()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7950be-de07-41e8-8858-1f4042ee252c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f78069-c1d0-4bcd-96f9-197ec137f66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"ann\"] = df[\"ann\"].map(lambda x: [i + 2 for i in x])\n",
    "df[\"ann\"].explode().agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c543b19-5b84-44ac-8aa7-7016d6e3c14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"std\"] = df[\"ann\"].map(np.std)\n",
    "df[\"std\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab08276-65e9-4ea4-9c59-ff7bbb7d26b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c338a67-b426-4fbc-b735-70c54de9c7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df[\"ann\"].map(lambda x: x == [0, 2, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13949b69-8687-4970-ba92-455ba87e2a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = [0, 2, 4]\n",
    "np.diff(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d248d4a-3782-4e36-89dd-08dfdebe6bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def listeq(lst: list[int]) -> Callable[[list[int]], bool]:\n",
    "    def eq(el: list[int]) -> bool:\n",
    "        return lst == el\n",
    "\n",
    "    return eq\n",
    "\n",
    "\n",
    "def entropy(data: list[int]) -> float:\n",
    "    counts = np.bincount(data)\n",
    "    p = counts / len(data)\n",
    "    return -np.sum(p[p > 0] * np.log2(p[p > 0]))\n",
    "\n",
    "\n",
    "def gini_coefficient(data: list[int]) -> float:\n",
    "    if np.all(data == data[0]) or np.isclose(np.sum(data), 0):\n",
    "        return 0\n",
    "\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "\n",
    "    return (\n",
    "        2 * np.sum(np.arange(1, n + 1) * sorted_data) / (n * np.sum(sorted_data))\n",
    "    ) - (n + 1) / n\n",
    "\n",
    "\n",
    "def calculate_alpha(ratings: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Krippendorff's Alpha for a single example with nominal data.\n",
    "\n",
    "    :param ratings: List of ratings (integers or strings) for a single example by different raters.\n",
    "    :return: Krippendorff's Alpha as a float.\n",
    "    \"\"\"\n",
    "    arratings = np.array(ratings)\n",
    "\n",
    "    # Count the occurrences of each rating\n",
    "    _, counts = np.unique(arratings, return_counts=True)\n",
    "    n = len(arratings)\n",
    "\n",
    "    # Calculate observed disagreement (D_o)\n",
    "    D_o = sum(c * (c - 1) for c in counts)  # Pairwise comparisons for each category\n",
    "    D_o = 0 if n <= 1 else 1 - D_o / (n * (n - 1))\n",
    "\n",
    "    # Calculate expected disagreement (D_e)\n",
    "    D_e = 1 - sum((counts / n) ** 2)  # Prob. of random agreement for each category\n",
    "\n",
    "    # Calculate Krippendorff's Alpha\n",
    "    return 1 - D_o / D_e if D_e != 0 else 1  # Handle division by zero\n",
    "\n",
    "\n",
    "def observed_agreement_single_item(coder_codes: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the observed agreement among coders for a single item with K categories\n",
    "    according to the provided formula, using Counter for category counts and a\n",
    "    comprehension for agreement calculation.\n",
    "\n",
    "    Args:\n",
    "        coder_codes: A list of integers representing the codes assigned by each coder.\n",
    "\n",
    "    Returns:\n",
    "        The observed agreement as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    n_coders = len(coder_codes)\n",
    "    category_counts = Counter(coder_codes)\n",
    "\n",
    "    agreement = sum(n_k * (n_k - 1) for n_k in category_counts.values())\n",
    "\n",
    "    return agreement / (n_coders * (n_coders - 1))  # Normalize by total comparisons\n",
    "\n",
    "\n",
    "def calculate_agreement(\n",
    "    data: list[int], *, labels: list[int], weight_type: str\n",
    ") -> float:\n",
    "    \"\"\"Calculte the agreement between multiple raters on a single item.\n",
    "\n",
    "    The calculation is based on the average weighted difference between all pairs of\n",
    "    values in `data`. `labels` is used to determine the possible values in the data in\n",
    "    case the data doesn't represent all of them.\n",
    "\n",
    "    The final value is normalized to the range [0, 1] by dividing by the maximum possible\n",
    "    weighted difference.\n",
    "\n",
    "    Args:\n",
    "        data:\n",
    "            A list of integers representing the ratings from different raters. There\n",
    "            must be at least two items.\n",
    "        labels:\n",
    "            A list of integers specifying all potential rating values. This is used\n",
    "            to determine the range for normalization.\n",
    "        weight_type:\n",
    "            A string indicating the weighting scheme to use. Valid options: \"quadratic\",\n",
    "            \"linear\", \"binary\".\n",
    "\n",
    "    Returns:\n",
    "        A float in the range [0, 1] representing the normalized agreement between\n",
    "        raters.  A value of 0 indicates maximum disagreement, and a value of 1 indicates\n",
    "        perfect agreement.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            If `data` contains fewer than two values or if an invalid  `weight_type` is\n",
    "            provided.\n",
    "    \"\"\"\n",
    "    if len(data) < 2:\n",
    "        raise ValueError(\"Data must contain at least two values.\")\n",
    "\n",
    "    combinations = list(itertools.combinations(data, 2))\n",
    "\n",
    "    if weight_type == \"quadratic\":\n",
    "        disagreement = sum((x - y) ** 2 for x, y in combinations)\n",
    "        normaliser = (max(labels) - min(labels)) ** 2\n",
    "    elif weight_type == \"linear\":\n",
    "        disagreement = sum(abs(x - y) for x, y in combinations)\n",
    "        normaliser = abs(max(labels) - min(labels))\n",
    "    elif weight_type == \"binary\":\n",
    "        disagreement = sum(x != y for x, y in combinations)\n",
    "        normaliser = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid weight type: {weight_type}\")\n",
    "\n",
    "    k = disagreement / normaliser / len(combinations)\n",
    "    return 1 - k\n",
    "\n",
    "def randolph(data: list[int], *, labels: list[int]) -> float:\n",
    "    # Make sure the labels start at 0\n",
    "    if min(labels) != 0:  \n",
    "        data = [x - min(labels) for x in data]\n",
    "\n",
    "    table = np.zeros(len(labels))\n",
    "    np.add.at(table, data, 1)\n",
    "\n",
    "    n_rat = table.sum()\n",
    "\n",
    "    table2 = table**2\n",
    "    p_rat = (table2.sum() - n_rat) / (n_rat * (n_rat - 1.0))\n",
    "    p_mean = p_rat.mean()\n",
    "\n",
    "    # Uniform distribution instead of marginal frequency of categories\n",
    "    p_mean_exp = 1 / len(labels)\n",
    "    kappa = (p_mean - p_mean_exp) / (1 - p_mean_exp)\n",
    "    return kappa\n",
    "\n",
    "\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "metrics = dict(\n",
    "    entropy=lambda x: x[\"ann\"].map(entropy),\n",
    "    gini=lambda x: x[\"ann\"].map(gini_coefficient),\n",
    "    alpha=lambda x: x[\"ann\"].map(calculate_alpha),\n",
    "    agr=lambda x: x[\"ann\"].map(observed_agreement_single_item),\n",
    "    agr_q=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"quadratic\", labels=labels\n",
    "    ),\n",
    "    agr_l=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"linear\", labels=labels\n",
    "    ),\n",
    "    agr_b=lambda x: x[\"ann\"].apply(\n",
    "        calculate_agreement, weight_type=\"binary\", labels=labels\n",
    "    ),\n",
    "    randolph=lambda x: x[\"ann\"].apply(randolph, labels=labels),\n",
    ")\n",
    "\n",
    "dd = df.assign(**metrics)\n",
    "examples = [\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 1],\n",
    "    [1, 2, 3],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 2],\n",
    "    [0, 0, 3],\n",
    "    [0, 0, 4],\n",
    "    [0, 2, 4],\n",
    "    [0, 0, 0],\n",
    "    [0, 4, 4, 4, 4, 4],\n",
    "    [0, 1, 2, 3, 4, 4],\n",
    "]\n",
    "pd.concat(\n",
    "    [dd[dd[\"ann\"].map(listeq(lst))].iloc[0] for lst in examples],\n",
    "    axis=1,\n",
    ").transpose()[[\"ann\", *metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1336124-a2f8-44ae-939b-3bbd9f355520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd[dd.ann.map(len) == 6].drop_duplicates(\"ann\")[\n",
    "    [\"ann\", *metrics]\n",
    "].sort_values(\"agr\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
