{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from typing import Any, TypedDict\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9276c-1d63-4595-962e-c7bb3fa665f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheValue(TypedDict):\n",
    "    \"\"\"Cache value for a tuple of (question, answer, narrative).\n",
    "\n",
    "    val_annotations: list of Likert annotation value for the respective source.\n",
    "    annotation_sources: name of the source model from which the evaluated is.\n",
    "\n",
    "    Both lists are always of the same size, but that size varies.\n",
    "    \"\"\"\n",
    "\n",
    "    val_annotations: list[int]\n",
    "    annotation_sources: list[str]\n",
    "\n",
    "\n",
    "# The cache. The strings in the key tuple must be lower cased.\n",
    "Cache = dict[tuple[str, str, str], CacheValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(cache_fname: str) -> Cache:\n",
    "    with open(cache_fname, \"rb\") as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "\n",
    "def retrieve_from_cache(\n",
    "    cache: Cache, question: str, answer: str, narrative: str\n",
    ") -> CacheValue:\n",
    "    \"\"\"\n",
    "    Use question, answer and narrative to retrieve all associated values\n",
    "    Return failure if key not found\n",
    "    \"\"\"\n",
    "\n",
    "    key = (question.lower(), answer.lower(), narrative.lower())\n",
    "    try:\n",
    "        return cache[key]\n",
    "    except:\n",
    "        return {\"message\": \"Key not found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = load_cache(\"../artifacts/human_eval_cache.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344d9e4-1848-4f74-b9b6-c99d2cc9e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache2 = []\n",
    "for (q, a, n), v in cache.items():\n",
    "    cache2.append({'question': q, 'answer': a, 'narrative' : n, 'val_anns': v['val_annotations'], 'ann_src': v['annotation_sources']})\n",
    "len(cache2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d4370-96e4-487e-a0d0-54e15d341c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cache2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad829f-a284-4629-ae91-104507ff31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = set()\n",
    "for _, row in df.iterrows():\n",
    "    inputs.add(row['question'] + row['narrative'] + row['answer'])\n",
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0c9e1-fe52-40d3-afeb-3008a8dbc6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter([src for v in cache.values() for src in v['annotation_sources']])\n",
    "sum(c.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text: str) -> str:\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f46fa2-75a3-4518-846c-116f1cc38ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likert_scores(row: pd.Series, cache: Cache) -> list[int]:\n",
    "    answer = row[\"predicted_answer\"] if \"predicted_answer\" in row else row[\"answer\"]\n",
    "    answer = remove_punctuation(answer)\n",
    "\n",
    "    question = row[\"question\"]\n",
    "    narrative = row[\"narrative\"]\n",
    "    \n",
    "    info = cache[question.lower(), answer.lower(), narrative.lower()]\n",
    "    return info[\"val_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_avg_likert(df: pd.DataFrame, cache: Cache) -> None:\n",
    "    likerts: list[float] = []\n",
    "    for idx, row in df.iterrows():\n",
    "        likertscores = get_likert_scores(row, cache)\n",
    "        likerts.append(sum(likertscores) / len(likertscores))\n",
    "\n",
    "    avg = sum(likerts) / len(likerts)\n",
    "    print(f\"Overall avg Likert for all answers {round(avg, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_avg_binary_likert(df: pd.DataFrame, cache: Cache) -> None:\n",
    "    likerts: list[float] = []\n",
    "    for idx, row in df.iterrows():\n",
    "        likertscores = get_likert_scores(row, cache)\n",
    "        binary_likertscores = [0 if x < 1 else 1 for x in likertscores]\n",
    "        likerts.append(sum(binary_likertscores) / len(binary_likertscores))\n",
    "\n",
    "    avg = sum(likerts) / len(likerts)\n",
    "    print(f\"Overall avg binary Likert for all answers: {round(avg, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_numbers(df: pd.DataFrame, cache: Cache) -> None:\n",
    "    overall_avg_likert(df, cache)\n",
    "    overall_avg_binary_likert(df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_df_by_onto(df: pd.DataFrame, cache: Cache) -> None:\n",
    "    conseq_df = df[df[\"onto\"] == \"Consequence\"]\n",
    "    print(\"Consequence\")\n",
    "    get_all_numbers(conseq_df, cache)\n",
    "\n",
    "    goal_df = df[df[\"onto\"] == \"Goal seeking\"]\n",
    "    print(\"Goal seeking\")\n",
    "    get_all_numbers(goal_df, cache)\n",
    "\n",
    "    reac_df = df[df[\"onto\"] == \"Reactionary\"]\n",
    "    print(\"Reactionary\")\n",
    "    get_all_numbers(reac_df, cache)\n",
    "\n",
    "    desire_df = df[df[\"onto\"] == \"Desire\"]\n",
    "    print(\"Desire\")\n",
    "    get_all_numbers(desire_df, cache)\n",
    "\n",
    "    other_df = df[df[\"onto\"] == \"Other\"]\n",
    "    print(\"Other\")\n",
    "    get_all_numbers(other_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_df = pd.read_csv(\"../artifacts/hidden_test_set_ontology.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_to_ontology_dict = {\n",
    "    row['question_meta']: row['Ontology'] for _, row in ontology_df.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_onto_to_df(df: pd.DataFrame, meta_to_ontology_dict: dict[str, str]) -> pd.DataFrame:\n",
    "    ontos: list[str] = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            ontos.append(meta_to_ontology_dict[row[\"question_meta\"]])\n",
    "        except:\n",
    "            ontos.append(meta_to_ontology_dict[row[\"meta\"]])\n",
    "    df[\"onto\"] = ontos\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_count_dict = ontology_df[\"Ontology\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_w_n_separator.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_knowl_df = pd.read_csv(\n",
    "    \"../artifacts/model_predictions/t5base_w_n_separator_w_knowl.csv\"\n",
    ")\n",
    "t5_knowl_df = add_onto_to_df(t5_knowl_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_knowl_df = t5_knowl_df[t5_knowl_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_t5_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-animation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "t511b_df = pd.read_csv(\"../artifacts/model_predictions/t511b_w_n_separator.csv\")\n",
    "t511b_df = add_onto_to_df(t511b_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t511b_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t511b_df = t511b_df[t511b_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t511b_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_t511b_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is the t511b with top 3 diverse comet verbalized\n",
    "t511b_knowl_df = pd.read_csv(\n",
    "    \"../artifacts/model_predictions/t511b_w_n_separator_w_knowl.csv\"\n",
    ")\n",
    "t511b_knowl_df = add_onto_to_df(t511b_knowl_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t511b_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t511b_knowl_df = t511b_knowl_df[\n",
    "    t511b_knowl_df[\"is_ques_answerable\"] == \"Not Answerable\"\n",
    "]\n",
    "get_all_numbers(impl_t511b_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_t511b_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-angola",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_df = pd.read_csv(\"../artifacts/model_predictions/gpt3.csv\")\n",
    "gpt3_df = add_onto_to_df(gpt3_df, meta_to_ontology_dict)\n",
    "get_all_numbers(gpt3_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_gpt3_df = gpt3_df[gpt3_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_gpt3_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_gpt3_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_knowl_df = pd.read_csv(\"../artifacts/model_predictions/gpt3_w_knowl.csv\")\n",
    "gpt3_knowl_df = add_onto_to_df(gpt3_knowl_df, meta_to_ontology_dict)\n",
    "get_all_numbers(gpt3_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_gpt3_knowl_df = gpt3_knowl_df[\n",
    "    gpt3_knowl_df[\"is_ques_answerable\"] == \"Not Answerable\"\n",
    "]\n",
    "get_all_numbers(impl_gpt3_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_df_by_onto(impl_gpt3_knowl_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-violin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lyric-title",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-dietary",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gtup top3\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_tup_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-array",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gtupsep top3\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_tupsep_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-ontario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top1\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_verb_top1_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-state",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top5 diverse\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_verb_top5_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 original\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_verb_top3_original.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-report",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 diverse\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_verb_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-minnesota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 reranked\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base_verb_top3_reranked.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-joint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T5 Appendix D.3 format - no separator\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t5base.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "detailed-firmware",
   "metadata": {},
   "source": [
    "## 11B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gtup top3\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_tup_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gtupsep top3\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_tupsep_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-north",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top1\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_verb_top1_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-robinson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top5 diverse\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_verb_top5_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-protocol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 original\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_verb_top3_original.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-reminder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 diverse\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_verb_top3_diverse.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-jefferson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gverb. top3 reranked\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b_verb_top3_reranked.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-accreditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"T5 Appendix D.3 format - no separator\")\n",
    "t5_df = pd.read_csv(\"../artifacts/model_predictions/t511b.csv\")\n",
    "t5_df = add_onto_to_df(t5_df, meta_to_ontology_dict)\n",
    "get_all_numbers(t5_df, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d907633",
   "metadata": {},
   "outputs": [],
   "source": [
    "impl_t5_df = t5_df[t5_df[\"is_ques_answerable\"] == \"Not Answerable\"]\n",
    "get_all_numbers(impl_t5_df, cache)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
